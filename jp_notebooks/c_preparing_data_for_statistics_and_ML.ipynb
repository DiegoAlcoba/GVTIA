{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de los datos para análisis y Machine Learning\n",
    "En este notebook crearemos un *pipeline* de preprocesamiento de texto similar al visto al principio del estudio, pero más avanzado y haciendo uso de librerías como *spaCy* y *textacy*. Una vez completado, se obtendrá un texto limpio y tokenizado listo para su análisis.\n",
    "\n",
    "Para este caso, se va a hacer uso del dataset creado en el apartado anterior, con más de 2000 comentarios del repoositorio *zigbee2mqtt*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en los cuadernos anteriores, comenzaremos cargando unos ajustes predefinidos para la ejecución del entorno virtual de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working on a local system.\n",
      "Files will be searched relative to \"..\".\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "#Carga del archivo setup.py\n",
    "%run -i ../pyenv_settings/setup.py\n",
    "\n",
    "#Imports y configuraciones de gráficas\n",
    "%run \"$BASE_DIR/pyenv_settings/settings.py\"\n",
    "\n",
    "#Reset del entorno virtual al iniciar la ejecución\n",
    "#%reset -f\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "# to print output of all statements and not just the last\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# otherwise text between $ signs will be interpreted as formula and printed in italic\n",
    "pd.set_option('display.html.use_mathjax', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de los datos en Pandas\n",
    "Cargaremos el dataset creado anteriormente con todos los comentarios de un repositorio de Github en Pandas, concretamente el archivo .csv (hay dos idénticos, uno en formato .csv y otro en .json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ruta del archivo\n",
    "file_path = \"../data/output.csv\"\n",
    "\n",
    "#Carga del archivo en un DataFrame\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de empezar a trabajar con los datos, revisaremos el nombre de las columnas y se cambiarán por otros nombres más genéricos en caso de considerarse necesario para una mejor coprensión y maniobrabilidad con el documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url', 'html_url', 'issue_url', 'id', 'node_id', 'user', 'created_at',\n",
      "       'updated_at', 'author_association', 'body', 'reactions',\n",
      "       'performed_via_github_app'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el renombramiento de las columnas, definiremos un diccionario *column_mapping* en el que cada entrada corresponderá con el nombre de la columna original y el nuevo que se le dará. \n",
    "\n",
    "Si se considera que algunas columnas no son necesarias para el análisis, se pueden descartar nombrándolas como *None* o directamente sin incluirlas en el diccionario.\n",
    "\n",
    "Viendo las columnas con las que cuenta el DataFrame se ve a simple vista que hay algunas columnas irrelevantes para el estudio, como las URLs, node_id, fechas de creación y actualización del post, asociaciones y la columna \"performed_via_github_app\". Estas serán descartadas a continuación sin incluirlas en el diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1811</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1115280228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <td>{'login': 'Tanjohnson99', 'id': 97446509, 'node_id': 'U_kgDOBc7qbQ', 'avatar_url': 'https://private-avatars.githubusercontent.com/u/97446509?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>&gt; Fixed for me (Chrome) by opening **dev tools**, right clicking on the **reload button**, and selecting **\"Empty Cache and Hard Reload\"**\\r\\n\\r\\nWorking for me like this ! Thanks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                         1811\n",
       "id                                                                                                                                                                                                 1115280228\n",
       "user  {'login': 'Tanjohnson99', 'id': 97446509, 'node_id': 'U_kgDOBc7qbQ', 'avatar_url': 'https://private-avatars.githubusercontent.com/u/97446509?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaX...\n",
       "text                      > Fixed for me (Chrome) by opening **dev tools**, right clicking on the **reload button**, and selecting **\"Empty Cache and Hard Reload\"**\\r\\n\\r\\nWorking for me like this ! Thanks"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast #Para convertir cadenas JSON en objetos Python para la eliminación de campos innecesarios del campo 'user'\n",
    "\n",
    "column_mapping = {\n",
    "    'id' : 'id',\n",
    "    'user' : 'user',\n",
    "    'body' : 'text',\n",
    "    'reactions' : None,\n",
    "    'url' : None,\n",
    "    'html_url' : None,\n",
    "    'issue_url' : None,\n",
    "    'node_id' : None,\n",
    "    'created_at' : None,\n",
    "    'update_at' : None,\n",
    "    'author_association' : None,\n",
    "    'performed_via_github_app' : None\n",
    "}\n",
    "\n",
    "#Se definen las columnas que se mantendrán\n",
    "columns = [c for c in column_mapping.keys() if column_mapping[c] != None]\n",
    "\n",
    "#Seleccionar y renombrar las columnas\n",
    "df = df[columns].rename(columns=column_mapping)\n",
    "\n",
    "#Normalizamos la columna user para extraer únicamente la información que interesa\n",
    "# user_data = pd.json_normalize(df['user'])\n",
    "\n",
    "# #Asegurar que las columnas que nos interesan existen\n",
    "# if 'login' in user_data.columns and 'id' in user_data.columns:\n",
    "#     df[['login', 'id']] = user_data[['login', 'id']]\n",
    "# else:\n",
    "#     raise ValueError(\"Las columnas 'login' e 'id' no se encuentran en los datos normalizados de 'user'\")\n",
    "\n",
    "# #Se elimina la columna 'user' original\n",
    "# df = df.drop(columns=['user'])\n",
    "\n",
    "#Muestra de una entrada para comprobar que se ha ejecutado correctamente\n",
    "df.sample(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardado y carga de un Data Frame\n",
    "Para guardar el Data Frame en disco se hará uso de una base de datos SQL utilizando SQLite. No es necesario contar con conocimientos avanzados de SQL pues se hará uso de la librería *sqlite3* de python que integra todas las funciones necesarias para trabajar con este tipo de bases de datos, como mucho, se usarán sentencias SQL básicas para realizar acciones sobre la base de datos..\n",
    "\n",
    "Cuando guardamos el Data Frame en la base de datos, no se almacena el índice del Data Frame, y todos los datos ya existentes son sobreescritos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2678"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sqlite3 ya está importado en el archivo settings.py cargado al iniciar el programa\n",
    "\n",
    "#Damos nombre a la DB, nos conectamos a ella, guardamos los datos, y se cierra conexión\n",
    "db_name = \"zigbee2mqtt_comments.db\"\n",
    "con = sqlite3.connect(db_name)\n",
    "df.to_sql(\"comments\", con, index=False, if_exists=\"replace\")\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Data Frame se lee de forma muy sencilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(db_name)\n",
    "df = pd.read_sql(\"select * from comments\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de los datos\n",
    "Antes de la tokenización de los datos es necesario limpiar los datos recopilados de ruido innecesario y distintos formatos en el texto. Algunos ejemplos de estos pueden ser los caracteres especiales, URLs incluidas en los comentarios, etiquetas, emoticonos, etc.\n",
    "\n",
    "Para esta función se usarán expresiones regulares junto con la librería *regex* para detectar y eliminar todos estos elementos innecesarios para el posterior análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re -> importado en settings.py\n",
    "\n",
    "RE_SUSPICIOUS = re.compile(r'[&#<>{}\\[\\]\\\\]') #símbolos sospechosos de introducir ruido\n",
    "\n",
    "def impurity(text, min_len=10): #se ignoran textos de menos de 10 caracteres\n",
    "    if text == None or len(text) < min_len:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(RE_SUSPICIOUS.findall(text))/len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se procederá a depurar y eliminar el ruido en los comentarios de los posts extraídos del repositorio con el que hemos estado trabajando hasta este momento,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2678/2678 [00:00<00:00, 119613.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>impurity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>&gt; If I put this config in my zigbee2mqtt 1.25.0-1 and also the below in the config folder it doesn't work. \\n&gt; \\n&gt; \\n&gt; \\n&gt; data_path: /config/zigbee2mqtt\\n&gt; \\n&gt; socat:\\n&gt; \\n&gt;   enabled: false\\n&gt; \\...</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>Sure, done in #307.</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>&gt; &gt; Thanks mate. Gonna check this tomorrow in the afternoon to (hopefully) help you out. I'm now gonna take a nap.\\n&gt; \\n&gt; \\n&gt; \\n&gt; Mate i found the problem.\\n&gt; \\n&gt; if you reset to default values, t...</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>&gt; It seems to me that within the configuration tab of the 'Zigbee2MQTT' addon the following lines need to be present (and the rest removed):\\n&gt; \\n&gt; ```\\n&gt; \\n&gt; data_path: /config/zigbee2mqtt\\n&gt; \\n&gt;...</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>That works and shows correct state in HA.\\r\\n\\r\\nJust FYI - I forgot to mention before that `{{ value_json.tilt }}` needs to be \"{{ value_json.tilt }}\" to work.</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                         text  \\\n",
       "1877  > If I put this config in my zigbee2mqtt 1.25.0-1 and also the below in the config folder it doesn't work. \\n> \\n> \\n> \\n> data_path: /config/zigbee2mqtt\\n> \\n> socat:\\n> \\n>   enabled: false\\n> \\...   \n",
       "1902                                                                                                                                                                                      Sure, done in #307.   \n",
       "1866  > > Thanks mate. Gonna check this tomorrow in the afternoon to (hopefully) help you out. I'm now gonna take a nap.\\n> \\n> \\n> \\n> Mate i found the problem.\\n> \\n> if you reset to default values, t...   \n",
       "1884  > It seems to me that within the configuration tab of the 'Zigbee2MQTT' addon the following lines need to be present (and the rest removed):\\n> \\n> ```\\n> \\n> data_path: /config/zigbee2mqtt\\n> \\n>...   \n",
       "1446                                         That works and shows correct state in HA.\\r\\n\\r\\nJust FYI - I forgot to mention before that `{{ value_json.tilt }}` needs to be \"{{ value_json.tilt }}\" to work.   \n",
       "\n",
       "      impurity  \n",
       "1877      0.08  \n",
       "1902      0.05  \n",
       "1866      0.05  \n",
       "1884      0.05  \n",
       "1446      0.05  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se añade la columna \"impurity\" al Data Frame que mostrará el porcentaje de cada comentario\n",
    "df['impurity'] = df['text'].progress_apply(impurity, min_len=10)\n",
    "\n",
    "#Algunas muestras de los registros con más ruido\n",
    "df[['text', 'impurity']].sort_values(by='impurity', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa, el grado de impurezas no es demasiado elevado, pero si se omiten facilitará el trabajo el análisis, ademaś de que siempre se tiene que tener en cuenta debido a que se está trabajando con contenido generado por usuarios, y este puede ser un caso excepcional en el que no hay demasiado ruido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conteo de otras posibles palabras que pueden introducir ruido\n",
    "Se importará la función *count_words* utilizada en *1-textual_data* para realizar el conteo de palabras de otras etiquetas que no se han tenido en cuenta y que también pueden introducir ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2678/2678 [00:00<00:00, 109349.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;anonymous&gt;</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;redacted&gt;</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;/details&gt;</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;details&gt;</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;/summary&gt;</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;summary&gt;</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;REDACTED&gt;</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;template&gt;</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;/script&gt;</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;snip&gt;</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             freq\n",
       "token            \n",
       "<anonymous>    51\n",
       "<redacted>      5\n",
       "</details>      5\n",
       "<details>       5\n",
       "</summary>      5\n",
       "<summary>       5\n",
       "<REDACTED>      4\n",
       "<template>      4\n",
       "</script>       4\n",
       "<snip>          4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_words(df, column='tokens', preprocess=None, min_freq=2):\n",
    "\n",
    "    #procesa los tokens y actualiza el contador\n",
    "    def update(doc):\n",
    "        tokens = doc if preprocess is None else preprocess(doc)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    #crea el contador y recorre todos los datos\n",
    "    counter = Counter()\n",
    "    df[column].progress_map(update)\n",
    "\n",
    "    #transforma el contador a dataframe\n",
    "    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n",
    "    freq_df = freq_df.query('freq >= @min_freq')\n",
    "    freq_df.index.name = 'token'\n",
    "    \n",
    "    return freq_df.sort_values('freq', ascending=False)\n",
    "\n",
    "count_words(df, column='text', preprocess=lambda t: re.findall(r'<[\\w/]*>', t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminación de ruido con Expresiones Regulares\n",
    "Se va a crear una función que definirá una serie de expresiones regulares que serán utilizadas para detectar en el texto una serie de patrones que cumplen aquellas palabras susceptibles de introducir ruido. Estas serán sustituidas por texto plano o eliminadas directamente del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "def clean(text):\n",
    "    # convert html escapes like &amp; to characters.\n",
    "    text = html.unescape(text) \n",
    "    # tags like <tab>\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
    "    # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
    "    # text or code in brackets like [0]\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
    "    # standalone sequences of specials, matches &# but not #cool\n",
    "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text)\n",
    "    # standalone sequences of hyphens like --- or ==\n",
    "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
    "    # sequences of white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se aplicará esta función a la columna \"text\" del Data Frame que almacena los comentarios de los usuarios en el repositorio, además, se añadirá una nueva columna con el texto limpio, de modo que se pueda visualizar más fácilmente los cambios entre el texto original y el texto sin ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2678/2678 [00:00<00:00, 17652.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                         text  \\\n",
      "1208  Same problem since I installed my GLEDOPTO GL-C-009P today. \\n\\n```Exception in handle_state_message_received when handling msg on 'zigbee2mqtt/Toilet': '{\"brightness\":102,\"last_seen\":\"2022-12-05T...   \n",
      "476   I had to recreate the configuration.yaml in the Zigbee2mqtt folder. I first created a copie and then added all the devices to the new file. I had to remove references to groups and or devices.yaml...   \n",
      "290                                                                     This issue is stale because it has been open 30 days with no activity. Remove stale label or comment or this will be closed in 7 days   \n",
      "1112  BTW: the same hardware setup on the same base system Debian 11 but with homebridge 1.6. on board (zigbee2mqtt 1.29.2 and module homebridge-z2m 1.9.2) works perfect!\\r\\n\\r\\n[1/15/2023, 3:55:37 PM] ...   \n",
      "2120  I have a similar problem that external converters having no knowldege of \"zigbee-herdsman-converters/lib/xxx\", where xxx is a any dependency. Not sure if it's the same issue? Works perfectly with ...   \n",
      "\n",
      "                                                                                                                                                                                                   clean_text  \n",
      "1208  Same problem since I installed my GLEDOPTO GL-C-009P today. ```Exception in handle_state_message_received when handling msg on 'zigbee2mqtt/Toilet': '{\"brightness\":102,\"last_seen\":\"2022-12-05T18:5...  \n",
      "476   I had to recreate the configuration.yaml in the Zigbee2mqtt folder. I first created a copie and then added all the devices to the new file. I had to remove references to groups and or devices.yaml...  \n",
      "290                                                                     This issue is stale because it has been open 30 days with no activity. Remove stale label or comment or this will be closed in 7 days  \n",
      "1112  BTW: the same hardware setup on the same base system Debian 11 but with homebridge 1.6. on board (zigbee2mqtt 1.29.2 and module homebridge-z2m 1.9.2) works perfect! Homebridge v1.6.0 (HAP v0.11.0)...  \n",
      "2120  I have a similar problem that external converters having no knowldege of \"zigbee-herdsman-converters/lib/xxx\", where xxx is a any dependency. Not sure if it's the same issue? Works perfectly with ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['clean_text'] = df['text'].progress_apply(clean)\n",
    "\n",
    "#Muestras de la columna \"clean_text\"\n",
    "print(df[['text', 'clean_text']].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya se había indicado antes que con suerte la información extraída no contenía demasiado ruido, pese a eso, se puede ver a simple vista la diferencia entre algunos textos originales y los textos ya sin ruido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización de caracteres con *textacy*\n",
    "Caracteres especiales como los acentos, apóstrofes, diéresis, etc. pueden ser un problema a la hora de tokenizar un texto, por ello se normalizará sustituyendo estos caracteres por equivalentes ASCII para evitar así inconvenientes.\n",
    "\n",
    "Se utilizará la librería *textacy* creada para trabajar junto con *spaCy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy\n",
    "import textacy.preprocessing as tprep\n",
    "\n",
    "# En caso de que se cuente con una versión menor a la 0.11\n",
    "if textacy.__version__ < '0.11':\n",
    "    def normalize(text):\n",
    "        text = tprep.normalize_hyphenated_words(text)\n",
    "        text = tprep.normalize_quotation_marks(text)\n",
    "        text = tprep.normaliza_unicode(text)\n",
    "        text = tprep.remove_accents(text)\n",
    "\n",
    "        return text\n",
    "    \n",
    "else:\n",
    "    #En mi caso cuento con la versión 0.13\n",
    "    def normalize(text):\n",
    "        text = tprep.normalize.hyphenated_words(text)\n",
    "        text = tprep.normalize.quotation_marks(text)\n",
    "        text = tprep.normalize.unicode(text)\n",
    "        text = tprep.remove.accents(text)\n",
    "        text = tprep.replace.urls(text)\n",
    "        text = tprep.replace.emails(text)\n",
    "        text = tprep.replace.emojis(text)\n",
    "        \n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, se aplicará la normalización sobre el texto limpio sin ruido obtenido en el apartado anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2678/2678 [00:00<00:00, 2692.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                         text  \\\n",
      "322   Same result for 1.35.1-1 version backup and 1,5 year backwards even. Now I'm wondering where the device data should be if it is not in the addon's backup file.\\r\\n\\r\\nOnly these files are in the b...   \n",
      "2663                                                                                                                                                  Thanks for the report. This indeed also fixed my issue.   \n",
      "2356  > I have no idea how you guys got it working but no matter what I do, every time I start this addon it overwrites the /config/zigbee2mqtt/configuration.yaml file with its default content.\\r\\n> \\r\\...   \n",
      "1936       Maybe try a reinstall of Zigbee2mqtt?\\r\\nI had your issue, till I did a full upgrade of core and OS. Then I found I had the deCONZ addon still running, turned that off and it all works on my pi.   \n",
      "902   I have the same problem, everything was working fine yestarday, today Z2m won't work and I keep having the \"bad gateway\" message\\r\\n\\r\\nin the addon's logs I have the following:\\r\\n14:37:38] INFO:...   \n",
      "\n",
      "                                                                                                                                                                                                   clean_text  \\\n",
      "322   Same result for 1.35.1-1 version backup and 1,5 year backwards even. Now I'm wondering where the device data should be if it is not in the addon's backup file. Only these files are in the backup: ...   \n",
      "2663                                                                                                                                                  Thanks for the report. This indeed also fixed my issue.   \n",
      "2356  I have no idea how you guys got it working but no matter what I do, every time I start this addon it overwrites the /config/zigbee2mqtt/configuration.yaml file with its default content. Btw. can s...   \n",
      "1936          Maybe try a reinstall of Zigbee2mqtt? I had your issue, till I did a full upgrade of core and OS. Then I found I had the deCONZ addon still running, turned that off and it all works on my pi.   \n",
      "902   I have the same problem, everything was working fine yestarday, today Z2m won't work and I keep having the \"bad gateway\" message in the addon's logs I have the following: 14:37:38] INFO: Preparing...   \n",
      "\n",
      "                                                                                                                                                                                              normalized_text  \n",
      "322   Same result for 1.35.1-1 version backup and 1,5 year backwards even. Now I'm wondering where the device data should be if it is not in the addon's backup file. Only these files are in the backup: ...  \n",
      "2663                                                                                                                                                  Thanks for the report. This indeed also fixed my issue.  \n",
      "2356  I have no idea how you guys got it working but no matter what I do, every time I start this addon it overwrites the /config/zigbee2mqtt/configuration.yaml file with its default content. Btw. can s...  \n",
      "1936          Maybe try a reinstall of Zigbee2mqtt? I had your issue, till I did a full upgrade of core and OS. Then I found I had the deCONZ addon still running, turned that off and it all works on my pi.  \n",
      "902   I have the same problem, everything was working fine yestarday, today Z2m won't work and I keep having the \"bad gateway\" message in the addon's logs I have the following: 14:37:38] INFO: Preparing...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['normalized_text'] = df['clean_text'].progress_apply(normalize)\n",
    "\n",
    "#Muestras de la columna \"clean_text\"\n",
    "print(df[['text', 'clean_text', 'normalized_text']].sample(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
